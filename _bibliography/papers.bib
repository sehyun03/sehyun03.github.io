---
---

@string{CVPR = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),}}
@string{ECCV = {European Conference on Computer Vision (<b>ECCV</b>),}}
@string{ICCV = {International Conference on Computer Vision (<b>ICCV</b>),}}
@string{NEURIPS = {Conference on Neural Information Processing Systems (<b>NeurIPS</b>),}}
@string{IJCV = {International Journal of Computer Vision (<b>IJCV</b>),}}
@string{ICRA = {IEEE International Conference on Robotics and Automation (<b>ICRA</b>),}}
@string{arXiv = {arXiv preprint,}}

@inproceedings{kim2022adaptive,
  title={Adaptive Superpixel for Active Learning in Semantic Segmentation},
  author={Kim Hoyoung and Oh Minhyeon and Hwang Sehyun and Kwak Suha and Ok Jungseul},
  abstract={Learning semantic segmentation requires pixel-wise annotations, which can be time-consuming and expensive. To reduce the annotation cost, we propose a superpixel-based active learning (AL) framework, which collects a dominant label per superpixel instead. To be specific, it consists of adaptive superpixel and sieving mechanisms, fully dedicated to AL. At each round of AL, we adaptively merge neighboring pixels of similar learned features into superpixels. We then query a selected subset of these superpixels using an acquisition function assuming no uniform superpixel size. This approach is more efficient than existing methods, which rely only on innate features such as RGB color and assume uniform superpixel sizes. Obtaining a dominant label per superpixel drastically reduces annotators' burden as it requires fewer clicks. However, it inevitably introduces noisy annotations due to mismatches between superpixel and ground truth segmentation. To address this issue, we further devise a sieving mechanism that identifies and excludes potentially noisy annotations from learning. Our experiments on both Cityscapes and PASCAL VOC datasets demonstrate the efficacy of adaptive superpixel and sieving mechanisms.},
  booktitle=ICCV,
  year={2023},
  abbr={ICCV},
  arxiv={2303.16817},
  selected={true},
  img_path={assets/img/kim2023adaptive.png},
}

@inproceedings{hwang2022combating,
  title={Combating label distribution shift for active domain adaptation},
  author={Hwang Sehyun and Lee Sohyun and Kim Sungyeon and Ok Jungseul and Kwak Suha},
  abstract={We consider the problem of active domain adaptation (ADA) to unlabeled target data, of which subset is actively selected and labeled given a budget constraint. Inspired by recent analysis on a critical issue from label distribution mismatch between source and target in domain adaptation, we devise a method that addresses the issue for the first time in ADA. At its heart lies a novel sampling strategy, which seeks target data that best approximate the entire target distribution as well as being representative, diverse, and uncertain. The sampled target data are then used not only for supervised learning but also for matching label distributions of source and target domains, leading to remarkable performance improvement. On four public benchmarks, our method substantially outperforms existing methods in every adaptation scenario.},
  booktitle=ECCV,
  year={2022},
  abbr={ECCV},
  arxiv={2208.06604},
  selected={true},
  img_path={assets/img/hwang2023combating2.png},
  code={https://github.com/sehyun03/ADA-label-distribution-matching},
  pages={549--566},
  organization={Springer},
}

@inproceedings{kim2022debias,
  title={Learning debiased classifier with biased committee},
  author={Nayeong Kim and Sehyun Hwang and Sungsoo Ahn and Jaesik Park and Suha Kwak},
  abstract={Neural networks are prone to be biased towards spurious correlations between classes and latent attributes exhibited in a major portion of training data, which ruins their generalization capability. We propose a new method for training debiased classifiers with no spurious attribute label. The key idea is to employ a committee of classifiers as an auxiliary module that identifies bias-conflicting data, i.e., data without spurious correlation, and assigns large weights to them when training the main classifier. The committee is learned as a bootstrapped ensemble so that a majority of its classifiers are biased as well as being diverse, and intentionally fail to predict classes of bias-conflicting data accordingly. The consensus within the committee on prediction difficulty thus provides a reliable cue for identifying and weighting bias-conflicting data. Moreover, the committee is also trained with knowledge transferred from the main classifier so that it gradually becomes debiased along with the main classifier and emphasizes more difficult data as training progresses. On five real-world datasets, our method outperforms prior arts using no spurious attribute label like ours and even surpasses those relying on bias labels occasionally.},
  booktitle=NEURIPS,
  year={2022},
  abbr={NeurIPS},
  arxiv={2206.10843},
  selected={true},
  img_path={assets/img/kim2022debias2.png},
  code={https://github.com/Nayeong-V-Kim/LWBC},
}

@article{kim2022learning,
  title={Learning to Detect Semantic Boundaries with Image-Level Class Labels},
  author={Namyup Kim* and Sehyun Hwang* and Suha Kwak},
  abstract={This paper presents the first attempt to learn semantic boundary detection using image-level class labels as supervision. Our method starts by estimating coarse areas of object classes through attentions drawn by an image classification network. Since boundaries will locate somewhere between such areas of different classes, our task is formulated as a multiple instance learning (MIL) problem, where pixels on a line segment connecting areas of two different classes are regarded as a bag of boundary candidates. Moreover, we design a new neural network architecture that can learn to estimate semantic boundaries reliably even with uncertain supervision given by the MIL strategy. Our network is used to generate pseudo semantic boundary labels of training images, which are in turn used to train fully supervised models. The final model trained with our pseudo labels achieves an outstanding performance on the SBD dataset, where it is as competitive as some of previous arts trained with stronger supervision.},
  journal=IJCV,
  year={2022},
  abbr={IJCV},
  equal_contrib={true},
  selected={true},
  arxiv={2212.07579},
  img_path={assets/img/publication_preview/kim2022learning.jpg}
}