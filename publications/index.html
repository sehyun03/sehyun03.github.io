<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Sehyun Hwang</title> <meta name="author" content="Sehyun Hwang"/> <meta name="description" content="Sehyun's personal webpage. Based on [*folio](https://github.com/bogoli/-folio) design. "/> <meta name="keywords" content="sehyun"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/vs.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üó∫Ô∏è</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://sehyun03.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/zenburn.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Sehyun¬†</span>Hwang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/cv_sehyun.pdf" target="_blank" rel="noopener noreferrer">Curriculum Vitae</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> * indicates equal contribution. <h2 class="year">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kim2024active-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kim2024active-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kim2024active-1400.webp"></source> <img src="/assets/img/kim2024active.jpeg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kim2024active" class="col-sm-8"> <div class="title">Active Label Correction for Semantic Segmentation with Foundation Models</div> <div class="author"> Hoyoung Kim,¬† <em>Sehyun Hwang</em>,¬†Suha Kwak,¬† and Jungseul Ok (*equal contribution) </div> <div class="periodical"> <em>International Conference on Machine Learning (<b>ICML</b>),</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2403.10820" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/ml-postech/active-label-correction" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Training and validating models for semantic segmentation require datasets with pixel-wise annotations, which are notoriously labor-intensive. Although useful priors such as foundation models or crowdsourced datasets are available, they are error-prone. We hence propose an effective framework of active label correction (ALC) based on a design of correction query to rectify pseudo labels of pixels, which in turn is more annotator-friendly than the standard one inquiring to classify a pixel directly according to our theoretical analysis and user study. Specifically, leveraging foundation models providing useful zero-shot predictions on pseudo labels and superpixels, our method comprises two key techniques: (i) an annotator-friendly design of correction query with the pseudo labels, and (ii) an acquisition function looking ahead label expansions based on the superpixels. Experimental results on PASCAL, Cityscapes, and Kvasir-SEG datasets demonstrate the effectiveness of our ALC framework, outperforming prior methods for active semantic segmentation and label correction. Notably, utilizing our method, we obtained a revised dataset of PASCAL by rectifying errors in 2.6 million pixels in PASCAL dataset.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/lee2024extreme-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/lee2024extreme-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/lee2024extreme-1400.webp"></source> <img src="/assets/img/lee2024extreme.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="lee2023extreme" class="col-sm-8"> <div class="title">Extreme Point Supervised Instance Segmentation</div> <div class="author"> Hyeonjun Lee,¬† <em>Sehyun Hwang</em>,¬† and Suha Kwak </div> <div class="periodical"> <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>),</em> 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2405.20729" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> </div> <div class="abstract hidden"> <p>This paper introduces a new weakly supervised learning approach for instance segmentation using extreme points, i.e., the topmost, leftmost, bottommost, and rightmost points of an object. Although these points are readily available in the modern bounding box annotation process and offer strong clues for precise segmentation, they have received less attention in the literature. Motivated by this, our study explores extreme point supervised instance segmentation to further enhance performance at the same annotation cost with box-supervised methods. Our work considers extreme points as a part of the true instance mask and propagates them to identify potential foreground and background points, which are all together used for training a pseudo label generator. Then pseudo labels given by the generator are in turn used for supervised learning of our final model. Our model generates high-quality masks, particularly when the target object is separated into multiple parts, where previous box-supervised methods often fail. On three public benchmarks, our method significantly outperforms existing box-supervised methods, further narrowing the gap with its fully supervised counterpart.</p> </div> </div> </div> </li> </ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/hwang2023active-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/hwang2023active-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/hwang2023active-1400.webp"></source> <img src="/assets/img/hwang2023active.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hwang2023active" class="col-sm-8"> <div class="title">Active Learning for Semantic Segmentation with Multi-class Label Query</div> <div class="author"> <em>Sehyun Hwang</em>,¬†Sohyun Lee,¬†Hoyoung Kim,¬†Minhyeon Oh,¬†Jungseul Ok,¬† and Suha Kwak </div> <div class="periodical"> <em>Conference on Neural Information Processing Systems (<b>NeurIPS</b>),</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2309.09319" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/sehyun03/MulActSeg" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>This paper proposes a new active learning method for semantic segmentation. The core of our method lies in a new annotation query design. It samples informative local image regions (e.g., superpixels), and for each of such regions, asks an oracle for a multi-hot vector indicating all classes existing in the region. This multi-class labeling strategy is substantially more efficient than existing ones like segmentation, polygon, and even dominant class labeling in terms of annotation time per click. However, it introduces the class ambiguity issue in training since it assigns partial labels (i.e., a set of candidate classes) to individual pixels. We thus propose a new algorithm for learning semantic segmentation while disambiguating the partial labels in two stages. In the first stage, it trains a segmentation model directly with the partial labels through two new loss functions motivated by partial label learning and multiple instance learning. In the second stage, it disambiguates the partial labels by generating pixel-wise pseudo labels, which are used for supervised learning of the model. Equipped with a new acquisition function dedicated to the multi-class labeling, our method outperformed previous work on Cityscapes and PASCAL VOC 2012 while spending less annotation cost.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kim2023adaptive-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kim2023adaptive-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kim2023adaptive-1400.webp"></source> <img src="/assets/img/kim2023adaptive.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kim2022adaptive" class="col-sm-8"> <div class="title">Adaptive Superpixel for Active Learning in Semantic Segmentation</div> <div class="author"> Hoyoung Kim,¬†Minhyeon Oh,¬† <em>Sehyun Hwang</em>,¬†Suha Kwak,¬† and Jungseul Ok </div> <div class="periodical"> <em>International Conference on Computer Vision (<b>ICCV</b>),</em> 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2303.16817" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/ml-postech/adaptive-superpixel-for-active-learning-in-semantic-segmentation" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Learning semantic segmentation requires pixel-wise annotations, which can be time-consuming and expensive. To reduce the annotation cost, we propose a superpixel-based active learning (AL) framework, which collects a dominant label per superpixel instead. To be specific, it consists of adaptive superpixel and sieving mechanisms, fully dedicated to AL. At each round of AL, we adaptively merge neighboring pixels of similar learned features into superpixels. We then query a selected subset of these superpixels using an acquisition function assuming no uniform superpixel size. This approach is more efficient than existing methods, which rely only on innate features such as RGB color and assume uniform superpixel sizes. Obtaining a dominant label per superpixel drastically reduces annotators‚Äô burden as it requires fewer clicks. However, it inevitably introduces noisy annotations due to mismatches between superpixel and ground truth segmentation. To address this issue, we further devise a sieving mechanism that identifies and excludes potentially noisy annotations from learning. Our experiments on both Cityscapes and PASCAL VOC datasets demonstrate the efficacy of adaptive superpixel and sieving mechanisms.</p> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/hwang2023combating2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/hwang2023combating2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/hwang2023combating2-1400.webp"></source> <img src="/assets/img/hwang2023combating2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hwang2022combating" class="col-sm-8"> <div class="title">Combating label distribution shift for active domain adaptation</div> <div class="author"> <em>Sehyun Hwang</em>,¬†Sohyun Lee,¬†Sungyeon Kim,¬†Jungseul Ok,¬† and Suha Kwak </div> <div class="periodical"> <em>European Conference on Computer Vision (<b>ECCV</b>),</em> 2022 </div> <span style="color:red"><b>Qualcomm Innovation Fellowship Winner, Gold Prize at IPIU paper Award</b></span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2208.06604" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/sehyun03/ADA-label-distribution-matching" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>We consider the problem of active domain adaptation (ADA) to unlabeled target data, of which subset is actively selected and labeled given a budget constraint. Inspired by recent analysis on a critical issue from label distribution mismatch between source and target in domain adaptation, we devise a method that addresses the issue for the first time in ADA. At its heart lies a novel sampling strategy, which seeks target data that best approximate the entire target distribution as well as being representative, diverse, and uncertain. The sampled target data are then used not only for supervised learning but also for matching label distributions of source and target domains, leading to remarkable performance improvement. On four public benchmarks, our method substantially outperforms existing methods in every adaptation scenario.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/kim2022debias2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/kim2022debias2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/kim2022debias2-1400.webp"></source> <img src="/assets/img/kim2022debias2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kim2022debias" class="col-sm-8"> <div class="title">Learning debiased classifier with biased committee</div> <div class="author"> Nayeong Kim,¬† <em>Sehyun Hwang</em>,¬†Sungsoo Ahn,¬†Jaesik Park,¬† and Suha Kwak </div> <div class="periodical"> <em>Conference on Neural Information Processing Systems (<b>NeurIPS</b>),</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2206.10843" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> <a href="https://github.com/Nayeong-V-Kim/LWBC" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a> </div> <div class="abstract hidden"> <p>Neural networks are prone to be biased towards spurious correlations between classes and latent attributes exhibited in a major portion of training data, which ruins their generalization capability. We propose a new method for training debiased classifiers with no spurious attribute label. The key idea is to employ a committee of classifiers as an auxiliary module that identifies bias-conflicting data, i.e., data without spurious correlation, and assigns large weights to them when training the main classifier. The committee is learned as a bootstrapped ensemble so that a majority of its classifiers are biased as well as being diverse, and intentionally fail to predict classes of bias-conflicting data accordingly. The consensus within the committee on prediction difficulty thus provides a reliable cue for identifying and weighting bias-conflicting data. Moreover, the committee is also trained with knowledge transferred from the main classifier so that it gradually becomes debiased along with the main classifier and emphasizes more difficult data as training progresses. On five real-world datasets, our method outperforms prior arts using no spurious attribute label like ours and even surpasses those relying on bias labels occasionally.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-4"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/kim2022learning-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/kim2022learning-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/kim2022learning-1400.webp"></source> <img src="/assets/img/publication_preview/kim2022learning.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kim2022learning" class="col-sm-8"> <div class="title">Learning to Detect Semantic Boundaries with Image-Level Class Labels</div> <div class="author"> Namyup Kim*,¬† <em>Sehyun Hwang*</em>,¬† and Suha Kwak (*equal contribution) </div> <div class="periodical"> <em>International Journal of Computer Vision (<b>IJCV</b>),</em> 2022 </div> <span style="color:red"><b>Honorable Mention @ Samsung HumanTech Paper Award</b></span> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2212.07579" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Paper</a> </div> <div class="abstract hidden"> <p>This paper presents the first attempt to learn semantic boundary detection using image-level class labels as supervision. Our method starts by estimating coarse areas of object classes through attentions drawn by an image classification network. Since boundaries will locate somewhere between such areas of different classes, our task is formulated as a multiple instance learning (MIL) problem, where pixels on a line segment connecting areas of two different classes are regarded as a bag of boundary candidates. Moreover, we design a new neural network architecture that can learn to estimate semantic boundaries reliably even with uncertain supervision given by the MIL strategy. Our network is used to generate pseudo semantic boundary labels of training images, which are in turn used to train fully supervised models. The final model trained with our pseudo labels achieves an outstanding performance on the SBD dataset, where it is as competitive as some of previous arts trained with stronger supervision.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Sehyun Hwang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>